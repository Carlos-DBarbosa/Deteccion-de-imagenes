{"cells":[{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":526},"executionInfo":{"elapsed":17667,"status":"ok","timestamp":1606146505335,"user":{"displayName":"JUAN CAMILO BOLAÑOS ALDANA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggux81cuJNFA5mgbWon509GYPUifh2wRK59RFA-=s64","userId":"01354567107100615779"},"user_tz":300},"id":"SzJJOyYd8RZk","outputId":"ab9e293b-e7b3-4cda-93ef-00df12bbba0c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Uninstalling opencv-python-4.1.2.30:\n","  Successfully uninstalled opencv-python-4.1.2.30\n","Collecting opencv-contrib-python==3.4.2.17\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/29/fc60b2de1713aa92946992544329f20ccb5e4ba26290f403e04b7da44105/opencv_contrib_python-3.4.2.17-cp36-cp36m-manylinux1_x86_64.whl (30.6MB)\n","\u001b[K     |████████████████████████████████| 30.6MB 144kB/s \n","\u001b[?25hCollecting numpy\u003e=1.11.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/86/753182c9085ba4936c0076269a571613387cdb77ae2bf537448bfd63472c/numpy-1.19.4-cp36-cp36m-manylinux2010_x86_64.whl (14.5MB)\n","\u001b[K     |████████████████████████████████| 14.5MB 332kB/s \n","\u001b[31mERROR: imgaug 0.2.9 requires opencv-python, which is not installed.\u001b[0m\n","\u001b[31mERROR: dopamine-rl 1.0.5 requires opencv-python\u003e=3.4.1.15, which is not installed.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 requires opencv-python, which is not installed.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.3.0 has requirement numpy\u003c1.19.0,\u003e=1.16.0, but you'll have numpy 1.19.4 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug\u003c0.2.7,\u003e=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy, opencv-contrib-python\n","  Found existing installation: numpy 1.18.5\n","    Uninstalling numpy-1.18.5:\n","      Successfully uninstalled numpy-1.18.5\n","  Found existing installation: opencv-contrib-python 4.1.2.30\n","    Uninstalling opencv-contrib-python-4.1.2.30:\n","      Successfully uninstalled opencv-contrib-python-4.1.2.30\n","Successfully installed numpy-1.19.4 opencv-contrib-python-3.4.2.17\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["cv2","numpy"]}}},"metadata":{"tags":[]},"output_type":"display_data"}],"source":["!pip uninstall opencv-python -y\n","# downgrade OpenCV a bit since some none-free features are not avilable\n","!pip install opencv-contrib-python==3.4.2.17 --force-reinstall\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":59232,"status":"ok","timestamp":1606146421286,"user":{"displayName":"JUAN CAMILO BOLAÑOS ALDANA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggux81cuJNFA5mgbWon509GYPUifh2wRK59RFA-=s64","userId":"01354567107100615779"},"user_tz":300},"id":"D3GHvqQR9pQS","outputId":"16189a79-0986-439e-e8be-ce55bd999081"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6494,"status":"ok","timestamp":1606146613307,"user":{"displayName":"JUAN CAMILO BOLAÑOS ALDANA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggux81cuJNFA5mgbWon509GYPUifh2wRK59RFA-=s64","userId":"01354567107100615779"},"user_tz":300},"id":"YDEyJekF99oj","outputId":"aa4c8549-4e2c-47cb-e0f0-63e9e6a1a2a0"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/My Drive/Septimo semestre/Procesamiento de imagen digital/detección de imágenes/Nintendo\n","corazon   mario      pickmin\t   prueba2.jpg\tprueba6.jpg\n","link\t  mario.jpg  pickmin.jpg   prueba3.jpg\tprueba7.jpg\n","link.jpg  mario.wav  pickmin.wav   prueba4.jpg\tprueba8.jpg\n","link.wav  photo.jpg  prueba10.jpg  prueba5.jpg\tprueba9.jpg\n"]}],"source":["import os\n","path='/content/drive/My Drive/Septimo semestre/Procesamiento de imagen digital/detección de imágenes/Nintendo'\n","os.chdir(path)\n","!pwd\n","!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":517},"id":"avmqEwPd-GpX"},"outputs":[{"data":{"application/javascript":["\n","    async function takePhoto(quality) {\n","      const div = document.createElement('div');\n","      const capture = document.createElement('button');\n","      capture.textContent = 'Capture';\n","      div.appendChild(capture);\n","\n","      const video = document.createElement('video');\n","      video.style.display = 'block';\n","      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","\n","      document.body.appendChild(div);\n","      div.appendChild(video);\n","      video.srcObject = stream;\n","      await video.play();\n","\n","      // Resize the output to fit the video element.\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","\n","      // Wait for Capture to be clicked.\n","      await new Promise((resolve) =\u003e capture.onclick = resolve);\n","\n","      const canvas = document.createElement('canvas');\n","      canvas.width = video.videoWidth;\n","      canvas.height = video.videoHeight;\n","      canvas.getContext('2d').drawImage(video, 0, 0);\n","      stream.getVideoTracks()[0].stop();\n","      div.remove();\n","      return canvas.toDataURL('image/jpeg', quality);\n","    }\n","    "],"text/plain":["\u003cIPython.core.display.Javascript object\u003e"]},"metadata":{},"output_type":"display_data"},{"ename":"AttributeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-52-b45569683d4a\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Load the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 12\u001b[0;31m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtake_photo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#tomamos una foto de la camara\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mimage1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'photo.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#leemos la foto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtraining_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#cambiamos su modelo de color de BGR a RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m\u003cipython-input-41-a39866ed0b9a\u003e\u001b[0m in \u001b[0;36mtake_photo\u001b[0;34m(filename, quality)\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'takePhoto({})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquality\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 42\u001b[0;31m   \u001b[0mbinary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb64decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"]}],"source":["\n","import cv2\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from itertools import product\n","from IPython.display import Audio\n","from scipy.io import wavfile\n","\n","%matplotlib inline\n","\n","# Load the image\n","p = take_photo()#tomamos una foto de la camara\n","image1 = cv2.imread('photo.jpg')#leemos la foto \n","training_image = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)#cambiamos su modelo de color de BGR a RGB\n","training_gray = cv2.cvtColor(training_image, cv2.COLOR_RGB2GRAY)#cambiamos su modelo de color de RGB a escala de grises\n","bordes = cv2.Canny(training_gray, 90, 200)# encontramos los bordes de la imagen\n","training_gray2 = cv2.GaussianBlur(training_gray, (7, 7), 3)#pasamos un filtro blur \n","\n","\n","_, contours, _ = cv2.findContours(bordes, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)#encontramos los contornos de la imagen\n","\n","areas = [cv2.contourArea(c) for c in contours]# encontramos el contorno mas grande\n","areaMax= np.argmax(areas)\n","\n","mask = np.zeros_like(training_gray) # creamos una mascara del tamaño de la imagen\n","cv2.drawContours(mask, contours, areaMax, 255, -1)\n","out = np.zeros_like(training_gray) # enmascaramos la seccion de interes, que en este caso son las cartas\n","out[mask == 255] = training_gray[mask == 255]\n","\n","(x, y) = np.where(mask == 255)\n","(topx, topy) = (np.min(x), np.min(y))# recortamos la imagen para que solo quede la parte de la camara\n","(bottomx, bottomy) = (np.max(x), np.max(y))\n","out = out[topx:bottomx+1, topy:bottomy+1]\n","\n","des,car = sacarCaracterisricas(out)#encontramos las caracterisicas y el descriptor de la imagen recortada\n","\n","print(car)\n","mat=[];\n","num = 0\n","fig = 0\n","lmayor = 0\n","\n","ranks = ['mario','link','pickmin']\n","#for s, r in product(suits, ranks): \n","for r in ranks:#recorremos el arreglo con las cartas\n","    stringImg =r+'.jpg'\n","    print(stringImg)  \n","    l = compararImg(des,r)#buscamos matches entre la imagen de prueba y la foto que tomamos\n","  \n","    if r=='pickmin':\n","       l=l*1.01 #hacemos un pequeño ajuste a la cantidad de matches con la imagen de prueba de los pickmin\n","    print(l)\n","    if l\u003e=lmayor:\n","      lmayor=l\n","      num=r#encontramos la carta con mayor cantidad de matches \n","      #fig=s\n","print(\"la carta es \"+num)#la imprimimos \n","imagen = cv2.imread(num+'.jpg')\n","\n","imagenFinal = cv2.cvtColor(imagen, cv2.COLOR_BGR2RGB)\n","\n","fx, plots = plt.subplots(1, 2, figsize=(20,10))\n","\n","plots[0].set_title(\"Foto de entrada\")\n","plots[0].imshow(out)\n","\n","plots[1].set_title(\"Carta identificada\")\n","plots[1].imshow(imagenFinal)\n","\n","data = wavfile.read(num+\".wav\")\n","\n","framerate = data[0]\n","sounddata = data[1]\n","time = np.arange(0,len(sounddata))/framerate\n","\n","Audio(sounddata,rate=framerate,autoplay=True)\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1915,"status":"ok","timestamp":1606146524899,"user":{"displayName":"JUAN CAMILO BOLAÑOS ALDANA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggux81cuJNFA5mgbWon509GYPUifh2wRK59RFA-=s64","userId":"01354567107100615779"},"user_tz":300},"id":"gKFwzGt1-acG"},"outputs":[],"source":["def compararImg(dO,s):\n","    #sift = cv2.xfeatures2d.SIFT_create() # intanciamos algoritmo sift\n","    #surf = cv2.xfeatures2d.SURF_create() # intanciamos algoritmo surf\n","    #orb = cv2.ORB_create()  # intanciamos algoritmo orb\n","    Odescriptor = dO\n","    Pdescriptor = load(s)#cargamos el descriptor de la imagen de entrenamiento correspondiente\n","    #Pkeypoints, Pdescriptor = surf.detectAndCompute(imgP, None)#encontramos los descriptores y caracteristicas de la imagen de entrenamiento\n","    #save(s,Pdescriptor)#guardamos en un archivo el descriptor \n","    #print(r+s)\n","    bf = cv2.BFMatcher(cv2.NORM_L1, crossCheck = True)#instanciamos el objeto que va a calcular los martches\n","    \n","    matches = bf.match(Odescriptor, Pdescriptor)#encontramos los matches entre la foto recortada y la imagen de entrenamiento\n","    matches = sorted(matches, key = lambda x : x.distance)#ajustamos los matches para dejar los mas cercanos\n","\n","    return len(matches)\n","    \n","def sacarCaracterisricas(img):\n","    #sift = cv2.xfeatures2d.SIFT_create()\n","    surf = cv2.xfeatures2d.SURF_create()\n","    #orb = cv2.ORB_create()\n","    Okeypoints, Odescriptor = surf.detectAndCompute(img, None)\n","    return Odescriptor,len(Okeypoints)"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3617,"status":"ok","timestamp":1606146523952,"user":{"displayName":"JUAN CAMILO BOLAÑOS ALDANA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggux81cuJNFA5mgbWon509GYPUifh2wRK59RFA-=s64","userId":"01354567107100615779"},"user_tz":300},"id":"UR4IYBt8x6Gx"},"outputs":[],"source":["import pickle\n","def save(filename,object):\n","    file=open(filename,'wb')#abrimos el archivo filename si no existe se crea\n","    pickle.dump(object,file)#sobreescribimos el archivo\n","    file.close()#cerramos y guardamos el archivo\n","    print(\"lo guarde\")\n","\n","def load(filename):\n","    file=open(filename,'rb')\n","    object=pickle.load(file)#traemos los datos dentro del archivo y lo guardamos en la variable object\n","    file.close()\n","    return object"]},{"cell_type":"code","execution_count":41,"metadata":{"executionInfo":{"elapsed":1338,"status":"ok","timestamp":1606162459589,"user":{"displayName":"JUAN CAMILO BOLAÑOS ALDANA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggux81cuJNFA5mgbWon509GYPUifh2wRK59RFA-=s64","userId":"01354567107100615779"},"user_tz":300},"id":"kKUpEh0o3W0V"},"outputs":[],"source":["from IPython.display import display, Javascript\n","from google.colab.output import eval_js\n","from base64 import b64decode\n","\n","#Codigo de:\n","#https://colab.research.google.com/notebooks/snippets/advanced_outputs.ipynb\n","\n","def take_photo(filename='photo.jpg', quality=0.8):\n","  js = Javascript('''\n","    async function takePhoto(quality) {\n","      const div = document.createElement('div');\n","      const capture = document.createElement('button');\n","      capture.textContent = 'Capture';\n","      div.appendChild(capture);\n","\n","      const video = document.createElement('video');\n","      video.style.display = 'block';\n","      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","\n","      document.body.appendChild(div);\n","      div.appendChild(video);\n","      video.srcObject = stream;\n","      await video.play();\n","\n","      // Resize the output to fit the video element.\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","\n","      // Wait for Capture to be clicked.\n","      await new Promise((resolve) =\u003e capture.onclick = resolve);\n","\n","      const canvas = document.createElement('canvas');\n","      canvas.width = video.videoWidth;\n","      canvas.height = video.videoHeight;\n","      canvas.getContext('2d').drawImage(video, 0, 0);\n","      stream.getVideoTracks()[0].stop();\n","      div.remove();\n","      return canvas.toDataURL('image/jpeg', quality);\n","    }\n","    ''')\n","  display(js)\n","  data = eval_js('takePhoto({})'.format(quality))\n","  binary = b64decode(data.split(',')[1])\n","  with open(filename, 'wb') as f:\n","    f.write(binary)\n","  return filename"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"deteccion.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}